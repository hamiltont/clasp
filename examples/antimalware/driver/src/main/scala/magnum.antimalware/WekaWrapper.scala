package magnum.antimalware

object WekaWrapper {
  import java.io.{File,FileWriter}
  import java.util.Random
  import weka.core.Instances
  import weka.core.converters.ArffLoader
  import weka.classifiers.{Classifier,Evaluation}

  // Classifiers.
  import weka.classifiers.bayes.{BayesNet,NaiveBayes}
  import weka.classifiers.functions.{Logistic,MultilayerPerceptron}
  import weka.classifiers.trees.{J48,RandomForest}

  def run(mode: String) {
    try {
      combineAllArffs(mode)

      val resultsDir = new File("Results")
      resultsDir.mkdir

      var arffLoader = new ArffLoader
      val trainingArffFile = new File(s"Arff/Training.arff")
      arffLoader.setFile(trainingArffFile)
      val train = arffLoader.getDataSet
      train.setClassIndex(train.numAttributes-1)

      if (mode == "Training") {
        val cvDir = new File("Results/CV")
        org.apache.commons.io.FileUtils.deleteDirectory(cvDir) 
        cvDir.mkdir

        // TODO Do these need any options?
        crossValidate(new BayesNet, "BayesNet", train)
        crossValidate(new NaiveBayes, "NaiveBayes", train)
        crossValidate(new Logistic, "Logistic", train)
        crossValidate(new MultilayerPerceptron, "MultilayerPerceptron",
                      train)
        crossValidate(new J48, "J48", train)
        crossValidate(new RandomForest, "RandomForest", train)
      } else {
        val ttDir = new File("Results/TrainTest")
        org.apache.commons.io.FileUtils.deleteDirectory(ttDir) 
        val ttApkDir = new File("Results/TrainTest/APKs")
        ttDir.mkdir; ttApkDir.mkdir;

        arffLoader.reset
        val testingArffFile = new File(s"Arff/Testing.arff")
        arffLoader.setFile(testingArffFile)
        val test = arffLoader.getDataSet
        test.setClassIndex(test.numAttributes-1)
        collectiveTest(new BayesNet, "BayesNet", train, test)
        collectiveTest(new NaiveBayes, "NaiveBayes", train, test)
        collectiveTest(new Logistic, "Logistic", train, test)
        collectiveTest(new MultilayerPerceptron, "MultilayerPerceptron",
                       train, test)
        collectiveTest(new J48, "J48", train, test)
        collectiveTest(new RandomForest, "RandomForest", train, test)

        individualTest(new BayesNet, "BayesNet", train)
        individualTest(new NaiveBayes, "NaiveBayes", train)
        individualTest(new Logistic, "Logistic", train)
        individualTest(new MultilayerPerceptron, "MultilayerPerceptron",
                       train)
        individualTest(new J48, "J48", train)
        individualTest(new RandomForest, "RandomForest", train)
      }
    } catch {
      case e: Throwable => {
        println("Exception caught. Aborting.")
        e.printStackTrace
      }
    }
  }

  def combineAllArffs(mode: String) {
    var arffLoader = new ArffLoader
    val arffDir: File = new File(s"Arff/$mode")

    val arffList = arffDir.listFiles;
    var instances: Instances = null
    var structure: Instances = null

    if (arffList == null) {
      print(s"Warning: Arff list for '$mode' is empty.")
      return
    }

    for (arffFile <- arffList) {
      arffLoader.setFile(arffFile)
      if (instances == null) {
        instances = arffLoader.getDataSet
        structure = arffLoader.getStructure
      } else {
        var newInstances = arffLoader.getDataSet
        var i = 0
        while (i < newInstances.numInstances) {
          val instance = newInstances.instance(i)
          instances.add(instance)
          i += 1
        }
      }
      arffLoader.reset
    }

    val combinedFile = new File(s"Arff/$mode.arff")
    val fw = new FileWriter(combinedFile)
    fw.write(instances.toString)
    fw.close
  }

  def crossValidate(cls: Classifier, clsName: String, train: Instances) {
    // TODO: Suppress output from this?
    val eval = new Evaluation(train)
    eval.crossValidateModel(cls, train, 10, new Random(1)) //TODO: Seed?
    val title = "10-fold Cross Validation\n" +
                "========================"
    writeEval(title, s"Results/CV/$clsName.txt", eval)
  }

  def collectiveTest(cls: Classifier, name: String,
                     train: Instances, test: Instances) {
    cls.buildClassifier(train)
    var eval = new Evaluation(train)
    eval.evaluateModel(cls, test)
    val title = s"Train/Test - $name\n" +
                 "=========="
    writeEval(title, s"Results/TrainTest/$name.txt", eval)
  }

  def individualTest(cls: Classifier, clsName: String, train: Instances) {
    cls.buildClassifier(train)
    var eval = new Evaluation(train)

    var arffLoader = new ArffLoader
    val arffDir: File = new File(s"Arff/Testing")

    val arffList = arffDir.listFiles;
    var instances: Instances = null
    var structure: Instances = null

    if (arffList == null) {
      print(s"Warning: Arff list for 'Testing' is empty.")
      return
    }

    for (arffFile <- arffList) {
      val arffName = arffFile.getName
      arffLoader.setFile(arffFile)
      var instances = arffLoader.getDataSet
      instances.setClassIndex(instances.numAttributes-1)
      eval.evaluateModel(cls, instances)
      val title = s"Train/Test - $clsName - $arffName\n" +
                   "=========="
      writeEval(title, s"Results/TrainTest/APKs/$arffName.txt", eval)
      arffLoader.reset
    }
  }

  private def writeEval(title: String, fileName: String,
                        eval: Evaluation) {
    val file = new File(fileName)
    val fw = new FileWriter(file)
    fw.write(eval.toSummaryString(title, false))
    fw.write("\n")
    fw.write(eval.toClassDetailsString)
    fw.write("\n")
    fw.write(eval.toMatrixString)
    fw.close
  }
}
