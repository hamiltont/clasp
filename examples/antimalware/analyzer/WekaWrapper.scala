package magnum.antimalware

import scala.collection.mutable.ListBuffer
import scala.util.Random

import scala.sys.process._
import scala.language.postfixOps

import java.io.{File,FileWriter}

import weka.core.Instances
import weka.core.converters.ArffLoader
import weka.classifiers.{Classifier,Evaluation}

// Classifiers.
import weka.classifiers.bayes.{BayesNet,NaiveBayes}
import weka.classifiers.functions.{Logistic,MultilayerPerceptron}
import weka.classifiers.trees.{J48,RandomForest}

class WekaWrapper(arffTag: String, resultsTag: String,
    percentBenignTrain: Int, percentMaliciousTrain: Int, randomSeed: Long) {
  def run() {
    Random.setSeed(randomSeed)

    // Get lists of benign and malicious arffs.
    val (benignTrainingArffs, benignTestingArffs) =
      getArffs("benign", percentBenignTrain)
    val (maliciousTrainingArffs, maliciousTestingArffs) =
      getArffs("malicious", percentMaliciousTrain)
    val trainingArffs = benignTrainingArffs ++ maliciousTrainingArffs
    val testingArffs = benignTestingArffs ++ maliciousTestingArffs

    val resultsDirStr = s"../results/$resultsTag"
    val resultsDir = new File(resultsDirStr)
    org.apache.commons.io.FileUtils.deleteDirectory(resultsDir) 
    resultsDir.mkdir;

    val trainingCombinedArff = combineAllArffs(trainingArffs, "training")
    val testingCombinedArff = combineAllArffs(testingArffs, "testing")

    var arffLoader = new ArffLoader
    arffLoader.setFile(trainingCombinedArff)
    val train = arffLoader.getDataSet
    train.setClassIndex(train.numAttributes-1)

    /*
    // Let's remove training completely.
    // This pollutes the training set with testing feature vectors.
    // TODO: Hamilton, confirm we don't need this.
    if (mode == "Training") {
      val cvDir = new File("Results/CV")
      org.apache.commons.io.FileUtils.deleteDirectory(cvDir) 
      cvDir.mkdir

      // TODO Do these need any options?
      crossValidate(new BayesNet, "BayesNet", train)
      crossValidate(new NaiveBayes, "NaiveBayes", train)
      crossValidate(new Logistic, "Logistic", train)
      crossValidate(new MultilayerPerceptron, "MultilayerPerceptron",
                    train)
      crossValidate(new J48, "J48", train)
      crossValidate(new RandomForest, "RandomForest", train)
    } else {
      */
    val ttStr = s"$resultsDir/traintest"
    val ttDir = new File(ttStr)
    org.apache.commons.io.FileUtils.deleteDirectory(ttDir) 
    ttDir.mkdir;

    arffLoader.reset
    arffLoader.setFile(testingCombinedArff)
    val test = arffLoader.getDataSet
    test.setClassIndex(test.numAttributes-1)
    collectiveTest(new BayesNet, "BayesNet", train, test, ttStr)
    collectiveTest(new NaiveBayes, "NaiveBayes", train, test, ttStr)
    collectiveTest(new Logistic, "Logistic", train, test, ttStr)
    collectiveTest(new MultilayerPerceptron, "MultilayerPerceptron",
                   train, test, ttStr)
    collectiveTest(new J48, "J48", train, test, ttStr)
    collectiveTest(new RandomForest, "RandomForest", train, test, ttStr)

    individualTest(new BayesNet, "BayesNet", train, testingArffs, ttStr)
    individualTest(new NaiveBayes, "NaiveBayes", train, testingArffs, ttStr)
    individualTest(new Logistic, "Logistic", train, testingArffs, ttStr)
    individualTest(new MultilayerPerceptron, "MultilayerPerceptron",
                   train, testingArffs, ttStr)
    individualTest(new J48, "J48", train, testingArffs, ttStr)
    individualTest(new RandomForest, "RandomForest", train, testingArffs, ttStr)
  }

  def getArffs(mode: String, percentTrain: Int):
      (ListBuffer[File], ListBuffer[File]) = {
    val arffDir: File = new File(s"../arff/$arffTag/$mode")
    val arffList = arffDir.listFiles

    if (arffList == null) {
      print(s"Warning: Arff list for '$mode' is empty.")
      return (ListBuffer[File](), ListBuffer[File]())
    }

    val shuffledIndices = util.Random.shuffle(List.range(0, arffList.length))
    var trainingArffs: ListBuffer[File] = new ListBuffer[File]()
    var testingArffs: ListBuffer[File] = new ListBuffer[File]()

    var i = 0;
    while (i < (percentTrain/100.0) * arffList.length) {
      trainingArffs += arffList(shuffledIndices(i))
      i += 1
    }
    while (i < arffList.length) {
      testingArffs += arffList(shuffledIndices(i))
      i += 1
    }

    return (trainingArffs, testingArffs)
  }

  def combineAllArffs(files: ListBuffer[File], mode: String): File = {
    var arffLoader = new ArffLoader
    var instances: Instances = null
    var structure: Instances = null

    for (arffFile <- files) {
      arffLoader.setFile(arffFile)
      if (instances == null) {
        instances = arffLoader.getDataSet
        structure = arffLoader.getStructure
      } else {
        var newInstances = arffLoader.getDataSet
        var i = 0
        while (i < newInstances.numInstances) {
          val instance = newInstances.instance(i)
          instances.add(instance)
          i += 1
        }
      }
      arffLoader.reset
    }

    val combinedFile = new File(s"../results/$resultsTag/$mode.arff")
    val fw = new FileWriter(combinedFile)
    fw.write(instances.toString)
    fw.close
    return combinedFile
  }

  /*
  def crossValidate(cls: Classifier, clsName: String, train: Instances) {
    // TODO: Suppress output from this?
    val eval = new Evaluation(train)
    eval.crossValidateModel(cls, train, 10, new Random(1)) //TODO: Seed?
    val title = "10-fold Cross Validation\n" +
                "========================"
    writeEval(title, s"Results/CV/$clsName.txt", eval)
  }
  */

  def collectiveTest(cls: Classifier, name: String,
                     train: Instances, test: Instances, traintest: String) {
    cls.buildClassifier(train)
    var eval = new Evaluation(train)
    eval.evaluateModel(cls, test)
    val title = s"Train/Test - $name\n" +
                 "=========="
    writeEval(title, s"$traintest/${name}Summary.txt", eval)
  }

  def individualTest(cls: Classifier, clsName: String, train: Instances,
      testArffList: ListBuffer[File], ttStr: String) {
    cls.buildClassifier(train)
    var eval = new Evaluation(train)
    var arffLoader = new ArffLoader

    var instances: Instances = null
    var structure: Instances = null

    val testDirStr = s"$ttStr/$clsName"
    val testDir = new File(testDirStr)
    testDir.mkdir;

    for (arffFile <- testArffList) {
      val arffName = arffFile.getName
      arffLoader.setFile(arffFile)
      var instances = arffLoader.getDataSet
      instances.setClassIndex(instances.numAttributes-1)
      eval.evaluateModel(cls, instances)
      val title = s"Train/Test - $clsName - $arffName\n" +
                   "=========="
      writeEval(title, s"$testDirStr/$arffName.txt", eval)
      arffLoader.reset
    }
  }

  private def writeEval(title: String, fileName: String,
                        eval: Evaluation) {
    val file = new File(fileName)
    val fw = new FileWriter(file)
    fw.write(eval.toSummaryString(title, false))
    fw.write("\n")
    fw.write(eval.toClassDetailsString)
    fw.write("\n")
    fw.write(eval.toMatrixString)
    fw.close
  }
}
