package magnum.antimalware

object WekaWrapper {
  import java.io.{File,FileWriter}
  import java.util.Random
  import weka.core.Instances
  import weka.core.converters.ArffLoader
  import weka.classifiers.{Classifier,Evaluation}

  // Classifiers.
  import weka.classifiers.bayes.{BayesNet,NaiveBayes}
  import weka.classifiers.functions.{Logistic,MultilayerPerceptron}
  import weka.classifiers.trees.{J48,RandomForest}

  def run(mode: String) {
    try {
      combineAllArffs(mode)

      val resultsDir = new File("Results")
      resultsDir.mkdir

      var arffLoader = new ArffLoader
      val trainingArffFile = new File(s"Arff/Training.arff")
      arffLoader.setFile(trainingArffFile)
      val train = arffLoader.getDataSet
      train.setClassIndex(train.numAttributes-1)

      if (mode == "Training") {
        val cvDir = new File("Results/CV")
        org.apache.commons.io.FileUtils.deleteDirectory(cvDir) 
        cvDir.mkdir

        // TODO Do these need any options?
        crossValidate(new BayesNet, "BayesNet", train)
        crossValidate(new NaiveBayes, "NaiveBayes", train)
        crossValidate(new Logistic, "Logistic", train)
        crossValidate(new MultilayerPerceptron, "MultilayerPerceptron", train)
        crossValidate(new J48, "J48", train)
        crossValidate(new RandomForest, "RandomForest", train)
      } else {
        arffLoader.reset
        val testingArffFile = new File(s"Arff/Testing.arff")
        arffLoader.setFile(testingArffFile)
        val test = arffLoader.getDataSet
        test.setClassIndex(test.numAttributes-1)
        collectiveTest(new BayesNet, "BayesNet", train, test)
      }
    } catch {
      case e: Throwable => {
        println("Exception caught. Aborting.")
        e.printStackTrace
      }
    }
  }

  def combineAllArffs(mode: String) {
    var arffLoader = new ArffLoader
    val arffDir: File = new File(s"Arff/$mode")

    val arffList = arffDir.listFiles;
    var instances: Instances = null
    var structure: Instances = null

    for (arffFile <- arffList) {
      arffLoader.setFile(arffFile)
      if (instances == null) {
        instances = arffLoader.getDataSet
        structure = arffLoader.getStructure
      } else {
        var newInstances = arffLoader.getDataSet
        var i = 0
        while (i < newInstances.numInstances) {
          val instance = newInstances.instance(i)
          instances.add(instance)
          i += 1
        }
      }
      arffLoader.reset
    }

    val combinedFile = new File(s"Arff/$mode.arff")
    val fw = new FileWriter(combinedFile)
    fw.write(instances.toString)
    fw.close
  }

  def crossValidate(cls: Classifier, name: String, train: Instances) {
    // TODO: Suppress output from this?
    val eval = new Evaluation(train)
    eval.crossValidateModel(cls, train, 10, new Random(1)) //TODO: Seed?
    val title = "10-fold Cross Validation\n" +
                "========================"
    writeEval(title, s"Results/CV/$name.txt", eval)
  }

  def collectiveTest(cls: Classifier, name: String,
                     train: Instances, test: Instances) {
    cls.buildClassifier(train)
    var eval = new Evaluation(train)
    eval.evaluateModel(cls, test)
    val title = "Train/Test\n" +
                "=========="
    writeEval(title, s"Results/TrainTest/$name.txt", eval)
  }

  private def writeEval(title: String, fileName: String,
                        eval: Evaluation) {
    val file = new File(fileName)
    val fw = new FileWriter(file)
    fw.write(eval.toSummaryString(title, false))
    fw.write("\n")
    fw.write(eval.toClassDetailsString)
    fw.write("\n")
    fw.write(eval.toMatrixString)
    fw.close
  }
}
